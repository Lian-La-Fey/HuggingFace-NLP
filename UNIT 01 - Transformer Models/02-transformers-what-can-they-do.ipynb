{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Transformers, ne yapabilirler ki?\n\nBu bölümde, Transformer modellerinin neler yapabileceğine bakacağız ve Transformers kütüphanesindeki ilk aracımızı kullanacağız: pipeline() fonksiyonu.\n\n## Transformers her yerde!\n\nTransformatör modelleri, önceki bölümde bahsedilenler gibi her türlü NLP görevini çözmek için kullanılır. Hugging Face ve Transformer modellerini kullanan ve aynı zamanda modellerini paylaşarak topluluğa katkıda bulunan şirket ve kuruluşlardan bazıları şunlardır:\n\n![image1](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/companies.PNG)\n\nTransformers kütüphanesi, bu paylaşılan modelleri oluşturmak ve kullanmak için işlevsellik sağlar. Model Hub'ı, herkesin indirip kullanabileceği binlerce önceden eğitilmiş model içerir. Ayrıca kendi modellerinizi de Hub'a yükleyebilirsiniz!\n\nTransformer modellerinin kaputun altında nasıl çalıştığını incelemeden önce, bazı ilginç NLP problemlerini çözmek için nasıl kullanılabileceklerine dair birkaç örneğe bakalım.","metadata":{}},{"cell_type":"markdown","source":"## Working with pipelines\n\nTransformers kütüphanesindeki en temel nesne `pipeline()` fonksiyonudur. Bir modeli gerekli ön işleme ve son işleme adımlarına bağlayarak herhangi bir metni doğrudan girmemize ve anlaşılır bir yanıt almamıza olanak tanır:","metadata":{"vscode":{"languageId":"plaintext"}}},{"cell_type":"code","source":"from transformers import pipeline\n\nclassifier = pipeline(\"sentiment-analysis\")\nclassifier(\"I've been waiting for a HuggingFace NLP course my whole life.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:48:31.216630Z","iopub.execute_input":"2024-08-01T13:48:31.217100Z","iopub.status.idle":"2024-08-01T13:48:59.540568Z","shell.execute_reply.started":"2024-08-01T13:48:31.217060Z","shell.execute_reply":"2024-08-01T13:48:59.539252Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-08-01 13:48:39.682700: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-01 13:48:39.682848: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-01 13:48:39.851303: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nNo model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8bd887e82024d75a0e5f514b3999675"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92e7323ac5f844f6ad4f4d5f1b84e200"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5af72ac6066a46178775dcd22c73d093"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13f6c805a19e428bbc23d7f18cf70ca7"}},"metadata":{}},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"[{'label': 'NEGATIVE', 'score': 0.9403972625732422}]"},"metadata":{}}]},{"cell_type":"code","source":"classifier(\"the sound is very low. the mic is bad. not to buy. I didn't expect it from Jbl.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:48:59.543448Z","iopub.execute_input":"2024-08-01T13:48:59.544436Z","iopub.status.idle":"2024-08-01T13:48:59.605818Z","shell.execute_reply.started":"2024-08-01T13:48:59.544378Z","shell.execute_reply":"2024-08-01T13:48:59.604558Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"[{'label': 'NEGATIVE', 'score': 0.9996776580810547}]"},"metadata":{}}]},{"cell_type":"code","source":"classifier(\n    [\"Not what I expected. same sound performance as a normal 50 TL headset.\",\n     \"It's quite handy. The cable is thick so it doesn't get tangled in my pocket.\"\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:48:59.607863Z","iopub.execute_input":"2024-08-01T13:48:59.608306Z","iopub.status.idle":"2024-08-01T13:48:59.718804Z","shell.execute_reply.started":"2024-08-01T13:48:59.608272Z","shell.execute_reply":"2024-08-01T13:48:59.717529Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[{'label': 'NEGATIVE', 'score': 0.9988583326339722},\n {'label': 'POSITIVE', 'score': 0.9967838525772095}]"},"metadata":{}}]},{"cell_type":"markdown","source":"Varsayılan olarak, bu işlem hattı İngilizce'de duygu analizi için ince ayarlanmış belirli bir ön eğitimli modeli seçer. Sınıflandırıcı nesnesini oluşturduğunuzda model indirilir ve önbelleğe alınır. Komutu yeniden çalıştırırsanız, bunun yerine önbelleğe alınan model kullanılır ve modeli tekrar indirmenize gerek kalmaz.","metadata":{}},{"cell_type":"markdown","source":"Bir pipeline'a metin aktardığınızda üç ana adım söz konusudur:\n\n1. Metin, modelin anlayabileceği bir formatta önceden işlenir.\n2. Önceden işlenmiş girdiler modele aktarılır.\n3. Modelin tahminleri sonradan işlenir, böylece bunları anlamlandırabilirsiniz.","metadata":{}},{"cell_type":"markdown","source":"Şu anda mevcut olan boru hatlarından bazıları şunlardır:\n\n- feature-extraction (get the vector representation of a text)\n- fill-mask\n- ner (named entity recognition)\n- question-answering\n- sentiment-analysis\n- summarization\n- text-generation\n- translation\n- zero-shot-classification","metadata":{}},{"cell_type":"markdown","source":"## Zero-shot classification\n\nEtiketlenmemiş metinleri sınıflandırmamız gereken daha zorlu bir görevi ele alarak başlayacağız. Bu, gerçek dünya projelerinde yaygın bir senaryodur çünkü metne açıklama eklemek genellikle zaman alır ve alan uzmanlığı gerektirir. Bu kullanım durumu için, zero-shot-classification pipeline'nı çok güçlüdür: sınıflandırma için hangi etiketlerin kullanılacağını belirlemenize olanak tanır, böylece önceden eğitilmiş modelin etiketlerine güvenmek zorunda kalmazsınız. Modelin bu iki etiketi kullanarak bir cümleyi nasıl pozitif veya negatif olarak sınıflandırabildiğini zaten gördünüz - ancak metni istediğiniz başka bir etiket kümesini kullanarak da sınıflandırabilir.","metadata":{}},{"cell_type":"code","source":"classifier = pipeline(\"zero-shot-classification\")\nclassifier(\n    \"This is a course about the Transformers library\",\n    candidate_labels=[\"education\", \"politics\", \"business\"],\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:48:59.722701Z","iopub.execute_input":"2024-08-01T13:48:59.723178Z","iopub.status.idle":"2024-08-01T13:49:12.668166Z","shell.execute_reply.started":"2024-08-01T13:48:59.723136Z","shell.execute_reply":"2024-08-01T13:49:12.666556Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"096c127035ca4025a8d312c7f6a8e371"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fb36096a8234fe0aef1fe27bb47cc0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9aa139849dac4d079209e112d8d81d5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3140094a82ff4de684567e71a71cae9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d12abf1e44474f91af6d61a4fc500a52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"722c26ea4af745edbee3282133ebfb50"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'sequence': 'This is a course about the Transformers library',\n 'labels': ['education', 'business', 'politics'],\n 'scores': [0.8445987105369568, 0.1119743064045906, 0.04342692345380783]}"},"metadata":{}}]},{"cell_type":"markdown","source":"Bu işlem hattına zero-shot denir çünkü kullanmak için verileriniz üzerinde modele ince ayar yapmanız gerekmez. İstediğiniz herhangi bir etiket listesi için olasılık puanlarını doğrudan döndürebilir!","metadata":{}},{"cell_type":"markdown","source":"## Text generation\n\nŞimdi metin oluşturmak için bir pipeline'ın nasıl kullanılacağını görelim. Buradaki ana fikir, sizin bir komut istemi sağlamanız ve modelin kalan metni oluşturarak bunu otomatik olarak tamamlamasıdır. Bu, birçok telefonda bulunan tahmini metin özelliğine benzer. Metin üretimi rastgelelik içerir, bu nedenle aşağıda gösterildiği gibi aynı sonuçları alamamanız normaldir.","metadata":{}},{"cell_type":"code","source":"generator = pipeline(\"text-generation\")\ngenerator(\"In this course, we will teach you how to\")","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:49:12.670918Z","iopub.execute_input":"2024-08-01T13:49:12.671492Z","iopub.status.idle":"2024-08-01T13:49:19.740395Z","shell.execute_reply.started":"2024-08-01T13:49:12.671440Z","shell.execute_reply":"2024-08-01T13:49:19.739327Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bdfe8674ade40f7a536d49606875c43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f41b5b02219f4721b366a58c437ad353"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42f4cd36576d4a2e8310f31340f266b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f818bcfe84254519897f57d9bee8691a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"375ecbb9ab9948d6a4d4d59110bb7f6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a4eb03ad6af4f338c2428dff6f32d61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"069279008d614fbbbc34ee819951a375"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': 'In this course, we will teach you how to create custom programs that automatically take care of some of your most recent problems. In both languages, we will explain different aspects of the programming that you can do with this program system as well, including example'}]"},"metadata":{}}]},{"cell_type":"markdown","source":"**num_return_sequences** argümanı ile kaç farklı dizinin oluşturulacağını ve **max_length** argümanı ile çıktı metninin toplam uzunluğunu kontrol edebilirsiniz.","metadata":{}},{"cell_type":"code","source":"generator(\n    \"In this course, we will teach you how to\",\n    num_return_sequences=2,\n    max_length=15\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:49:19.742150Z","iopub.execute_input":"2024-08-01T13:49:19.742527Z","iopub.status.idle":"2024-08-01T13:49:20.250182Z","shell.execute_reply.started":"2024-08-01T13:49:19.742496Z","shell.execute_reply":"2024-08-01T13:49:20.249108Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': 'In this course, we will teach you how to create a powerful app for'},\n {'generated_text': 'In this course, we will teach you how to use the built-in'}]"},"metadata":{}}]},{"cell_type":"markdown","source":"## Hub'daki herhangi bir modeli bir pipeline'da kullanma\n\nÖnceki örneklerde eldeki görev için varsayılan model kullanıldı, ancak belirli bir görev için (örneğin, metin oluşturma) bir işlem hattında kullanmak üzere Hub'dan belirli bir model de seçebilirsiniz. Model Hub'ına gidin ve yalnızca o görev için desteklenen modelleri görüntülemek için soldaki ilgili etikete tıklayın. Bunun gibi bir sayfaya ulaşmalısınız.\n\nDistilgpt2 modelini deneyelim! Daha önce olduğu gibi aynı pipeline'a nasıl yükleyeceğiniz aşağıda açıklanmıştır:","metadata":{}},{"cell_type":"code","source":"generator = pipeline(\n    task=\"text-generation\",\n    model=\"distilgpt2\"\n)\ngenerator(\n    \"In this course, we will teach you how to\",\n    max_length=45,\n    num_return_sequences=3,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:49:20.251420Z","iopub.execute_input":"2024-08-01T13:49:20.251749Z","iopub.status.idle":"2024-08-01T13:49:28.141004Z","shell.execute_reply.started":"2024-08-01T13:49:20.251720Z","shell.execute_reply":"2024-08-01T13:49:28.139608Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"218aafdeaac043eb957f052dec362a6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f546ea443529423fbc6e7a0f7c99a97a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10ece72732ba4f16946cf4b077f981b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7df167db7ea46a083ef9e89ec18ed41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5787df4f9eb240c2877382b5c1279d76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60ca3f8f171b43e0b6cef65243da0039"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce4e837e30e24d208dc2425d3483ad25"}},"metadata":{}},{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': 'In this course, we will teach you how to understand the power of knowledge for life. And we will make mistakes through it, and learn to be more responsible for our success.'},\n {'generated_text': \"In this course, we will teach you how to solve problem solving skills, and we'll also help you with learning some new concepts. So if you'd like to teach these courses before you're ready for it, don't\"},\n {'generated_text': 'In this course, we will teach you how to understand both the role of the C. diff, and the role of the diff. When we show you how to understand a diff in a diff, we will show you how'}]"},"metadata":{}}]},{"cell_type":"markdown","source":"Dil etiketlerine tıklayarak model aramanızı daraltabilir ve başka bir dilde metin üretecek bir model seçebilirsiniz. Model HUB, birden fazla dili destekleyen çok dilli modeller için kontrol noktaları bile içerir.\n\nÜzerine tıklayarak bir model seçtikten sonra, modeli doğrudan çevrimiçi olarak denemenizi sağlayan bir pencere öğesi olduğunu göreceksiniz. Bu şekilde modeli indirmeden önce yeteneklerini hızlıca test edebilirsiniz.","metadata":{}},{"cell_type":"markdown","source":"## Mask filling\n\nDeneyeceğiniz bir sonraki pipeline `fill-mask`'tır. Bu görevin amacı, verilen bir metindeki boşlukları doldurmaktır:","metadata":{}},{"cell_type":"code","source":"unmasker = pipeline(\"fill-mask\")\nunmasker(\"This course will teach you all about <mask> models.\", top_k=5)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:49:28.144886Z","iopub.execute_input":"2024-08-01T13:49:28.146408Z","iopub.status.idle":"2024-08-01T13:49:31.658055Z","shell.execute_reply.started":"2024-08-01T13:49:28.146321Z","shell.execute_reply":"2024-08-01T13:49:31.656820Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert/distilroberta-base and revision ec58a5b (https://huggingface.co/distilbert/distilroberta-base).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ff1913cd9bd4a5cb57577af5367e7c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31422d25ae9f4631b6a345fcfcaf4d50"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b90fd78dff4d4dcd93eefccd173f6bba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3772bbb601ef4ac18e3a067b609e7067"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c0d4407298648a99cbb85c0b052f29b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"896b75f2f00b48639b8767a124c800de"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.1961979866027832,\n  'token': 30412,\n  'token_str': ' mathematical',\n  'sequence': 'This course will teach you all about mathematical models.'},\n {'score': 0.04052741825580597,\n  'token': 38163,\n  'token_str': ' computational',\n  'sequence': 'This course will teach you all about computational models.'},\n {'score': 0.03301801159977913,\n  'token': 27930,\n  'token_str': ' predictive',\n  'sequence': 'This course will teach you all about predictive models.'},\n {'score': 0.03194144368171692,\n  'token': 745,\n  'token_str': ' building',\n  'sequence': 'This course will teach you all about building models.'},\n {'score': 0.02452291175723076,\n  'token': 3034,\n  'token_str': ' computer',\n  'sequence': 'This course will teach you all about computer models.'}]"},"metadata":{}}]},{"cell_type":"markdown","source":"`top_k` bağımsız değişkeni kaç olasılığın görüntülenmesini istediğinizi kontrol eder. Burada modelin, genellikle maske belirteci olarak adlandırılan özel `\\<mask\\>` sözcüğünü doldurduğunu unutmayın. Diğer maske doldurma modelleri farklı maske belirteçlerine sahip olabilir, bu nedenle diğer modelleri keşfederken uygun maske kelimesini doğrulamak her zaman iyidir. Bunu kontrol etmenin bir yolu, araçta kullanılan maske sözcüğüne bakmaktır.","metadata":{}},{"cell_type":"markdown","source":"## Named entity recognition\n\nAdlandırılmış varlık tanıma (NER), modelin girdi metninin hangi bölümlerinin kişiler, konumlar veya kuruluşlar gibi varlıklara karşılık geldiğini bulması gereken bir görevdir. Bir örneğe bakalım:","metadata":{}},{"cell_type":"code","source":"ner = pipeline(\n    task=\"ner\", grouped_entities=True\n)\nner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:49:31.659860Z","iopub.execute_input":"2024-08-01T13:49:31.660313Z","iopub.status.idle":"2024-08-01T13:49:40.973722Z","shell.execute_reply.started":"2024-08-01T13:49:31.660273Z","shell.execute_reply":"2024-08-01T13:49:40.972280Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c56983ac154c44269a48dce8c83d5f6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2e4e6177de54494a7c69ffc348b2624"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c913f435306d467eacef167de3d2a025"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b36d97f49c0845f18a077c19896d8365"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/token_classification.py:168: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[{'entity_group': 'PER',\n  'score': 0.9981694,\n  'word': 'Sylvain',\n  'start': 11,\n  'end': 18},\n {'entity_group': 'ORG',\n  'score': 0.9796019,\n  'word': 'Hugging Face',\n  'start': 33,\n  'end': 45},\n {'entity_group': 'LOC',\n  'score': 0.9932106,\n  'word': 'Brooklyn',\n  'start': 49,\n  'end': 57}]"},"metadata":{}}]},{"cell_type":"markdown","source":"Burada model Sylvain'in bir kişi (PER), Hugging Face'in bir kuruluş (ORG) ve Brooklyn'in bir konum (LOC) olduğunu doğru bir şekilde tespit etmiştir.\n\nPipeline oluşturma fonksiyonuna **grouped_entities=True** seçeneğini ekleyerek pipeline'a cümlenin aynı varlığa karşılık gelen kısımlarını bir araya getirmesini söylüyoruz: burada model \"Hugging\" ve \"Face\" isimlerini birden fazla kelimeden oluşmasına rağmen doğru bir şekilde tek bir organizasyon olarak gruplandırmıştır. Aslında, bir sonraki bölümde göreceğimiz gibi, ön işleme bazı kelimeleri daha küçük parçalara bile bölmektedir. Örneğin, Sylvain dört parçaya bölünmüştür: S, ##yl, ##va ve ##in. İşlem sonrası adımda, pipeline bu parçaları başarılı bir şekilde yeniden gruplandırmıştır.","metadata":{}},{"cell_type":"markdown","source":"## Question answering\n\nSoru yanıtlama pipeline'nı, belirli bir bağlamdaki bilgileri kullanarak soruları yanıtlar:","metadata":{}},{"cell_type":"code","source":"question_answerer  = pipeline(\"question-answering\")\nquestion_answerer (\n    question=\"Where do I work?\",\n    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T14:21:40.836657Z","iopub.execute_input":"2024-08-01T14:21:40.838182Z","iopub.status.idle":"2024-08-01T14:21:41.572325Z","shell.execute_reply.started":"2024-08-01T14:21:40.838127Z","shell.execute_reply":"2024-08-01T14:21:41.571065Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'score': 0.694976270198822, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"},"metadata":{}}]},{"cell_type":"code","source":"context = \"The Turing Test was designed by Alan Turing, the famous mathematician who developed the precursor to the modern computer. It is a supervised way of determining whether a machine is truly intelligent, i.e. whether it has a human-like mind. We can only perceive the mind by looking inside ourselves. The only reason we can do this is because we are our mental apparatus. Therefore, it is impossible for us to enter into the consciousness of another being. We can only experience our own mind. When it comes to the mind of the other, we need to read the signs that surface. The Turing Test is based on this principle. In the most famous variant of the test, the subject is asked to ask questions of something in a closed room, which can be either a human or a computer. To avoid mechanical problems with speech, the conversation is conducted with a keyboard and monitor. The questions typed on the keyboard are of the subject's choice, and the person or computer in the room sends their answers to the subject's monitor screen. If the subject cannot accurately distinguish whether it is a person or a computer in the room, the computer benefits from this ambiguity and is considered to have a mind.\"\nquestion = \"\"\"\nWhich of the following is not mentioned in this passage about the Turing Test? \nA) It has more than one type \nB) The flow of content is determined by the subject \nC) Focuses directly on the content of the mind \nD) That it is implemented in a controlled manner \nE) On what basic principle it is based\n\"\"\"\nquestion_answerer(question=question, context=context)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T14:23:26.534943Z","iopub.execute_input":"2024-08-01T14:23:26.535475Z","iopub.status.idle":"2024-08-01T14:23:26.926830Z","shell.execute_reply.started":"2024-08-01T14:23:26.535438Z","shell.execute_reply":"2024-08-01T14:23:26.925404Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'score': 0.0007389185484498739,\n 'start': 655,\n 'end': 722,\n 'answer': 'the subject is asked to ask questions of something in a closed room'}"},"metadata":{}}]},{"cell_type":"markdown","source":"Bu pipeline'nın sağlanan bağlamdan bilgi çıkararak çalıştığını unutmayın; yanıtı oluşturmaz.","metadata":{}},{"cell_type":"markdown","source":"## Summarization\n\nÖzetleme, bir metni, metinde atıfta bulunulan önemli hususların tümünü (veya çoğunu) koruyarak daha kısa bir metne indirgeme görevidir. İşte bir örnek:","metadata":{}},{"cell_type":"code","source":"summarizer = pipeline(\"summarization\")\nsummarizer(\n    \"\"\"\n    America has changed dramatically during recent years. Not only has the number of \n    graduates in traditional engineering disciplines such as mechanical, civil, \n    electrical, chemical, and aeronautical engineering declined, but in most of \n    the premier American universities engineering curricula now concentrate on \n    and encourage largely the study of engineering science. As a result, there \n    are declining offerings in engineering subjects dealing with infrastructure, \n    the environment, and related issues, and greater concentration on high \n    technology subjects, largely supporting increasingly complex scientific \n    developments. While the latter is important, it should not be at the expense \n    of more traditional engineering.\n\n    Rapidly developing economies such as China and India, as well as other \n    industrial countries in Europe and Asia, continue to encourage and advance \n    the teaching of engineering. Both China and India, respectively, graduate \n    six and eight times as many traditional engineers as does the United States. \n    Other industrial countries at minimum maintain their output, while America \n    suffers an increasingly serious decline in the number of engineering graduates \n    and a lack of well-educated engineers.\n\"\"\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T14:24:49.934865Z","iopub.execute_input":"2024-08-01T14:24:49.935379Z","iopub.status.idle":"2024-08-01T14:25:11.946153Z","shell.execute_reply.started":"2024-08-01T14:24:49.935325Z","shell.execute_reply":"2024-08-01T14:25:11.944058Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d647a9db24da4a0eb1d459c7f2829672"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fbeedc82a064febb59828a8f195009c"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80d1a9fb961645f082200d21c18fd2e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0abbb03d96ac4fa09f9c389cf850e788"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"903317e0cb5c412e9c14812a9cd08a28"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil,    electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India continue to encourage and advance the teaching of engineering .'}]"},"metadata":{}}]},{"cell_type":"markdown","source":"## Translation\n\nÇeviri için, görev adında bir dil çifti sağlarsanız (\"translation_en_to_fr\" gibi) varsayılan bir model kullanabilirsiniz, ancak en kolay yol Model Hub'ında kullanmak istediğiniz modeli seçmektir. Burada Fransızca'dan İngilizce'ye çeviri yapmayı deneyeceğiz:","metadata":{}},{"cell_type":"code","source":"translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\ntranslator(\"Ce cours est produit par Hugging Face.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-01T14:29:27.265242Z","iopub.execute_input":"2024-08-01T14:29:27.265780Z","iopub.status.idle":"2024-08-01T14:29:34.998359Z","shell.execute_reply.started":"2024-08-01T14:29:27.265745Z","shell.execute_reply":"2024-08-01T14:29:34.996876Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5991c5a810604fad927e1961d6de16dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8233940d4e74c65b7fb9aa8bad98305"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9cf1145dd594eecab65e0fb49f86dbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17e649263aa0499bb51cef52cecf3c9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db884bd9de1c43aaa8da0b62ac0496ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc7624e1a39f41a5932427e867a97b6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99d78e5d004b45d88de6aab269bf87c1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"[{'translation_text': 'This course is produced by Hugging Face.'}]"},"metadata":{}}]},{"cell_type":"markdown","source":"Metin oluşturma ve özetlemede olduğu gibi, sonuç için bir max_length veya min_length belirtebilirsiniz.","metadata":{}},{"cell_type":"markdown","source":"Şu ana kadar gösterilen pipeline'lar çoğunlukla gösterim amaçlıdır. Belirli görevler için programlanmışlardır ve bunların varyasyonlarını gerçekleştiremezler. Bir sonraki bölümde, bir pipeline() fonksiyonunun içinde ne olduğunu ve davranışını nasıl özelleştireceğinizi öğreneceksiniz.","metadata":{}}]}