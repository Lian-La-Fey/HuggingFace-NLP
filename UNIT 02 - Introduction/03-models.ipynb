{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Models\n\nBu bölümde bir model oluşturmaya ve kullanmaya daha yakından bakacağız. Herhangi bir modeli bir kontrol noktasından örneklemek istediğinizde kullanışlı olan AutoModel sınıfını kullanacağız.\n\nAutoModel sınıfı ve tüm akrabaları aslında kütüphanede bulunan çok çeşitli modeller üzerinde basit sarmalayıcılardır. Kontrol noktanız için uygun model mimarisini otomatik olarak tahmin edebildiği ve ardından bu mimariye sahip bir modeli örneklediği için akıllıca bir sarmalayıcıdır.\n\nAncak, kullanmak istediğiniz modelin türünü biliyorsanız, doğrudan mimarisini tanımlayan sınıfı kullanabilirsiniz. Bunun bir BERT modeli ile nasıl çalıştığına bir göz atalım.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## Creating a Transformer\n\nBir BERT modelini başlatmak için yapmamız gereken ilk şey bir yapılandırma nesnesi yüklemektir:","metadata":{}},{"cell_type":"code","source":"from transformers import BertConfig, BertModel\n\nconfig = BertConfig()\nmodel = BertModel(config)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:53:25.536601Z","iopub.execute_input":"2024-08-02T05:53:25.537026Z","iopub.status.idle":"2024-08-02T05:53:34.276472Z","shell.execute_reply.started":"2024-08-02T05:53:25.536990Z","shell.execute_reply":"2024-08-02T05:53:34.275314Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Yapılandırma(configuration), modeli oluşturmak için kullanılan birçok öznitelik içerir:","metadata":{}},{"cell_type":"code","source":"print(config)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:53:40.847393Z","iopub.execute_input":"2024-08-02T05:53:40.847820Z","iopub.status.idle":"2024-08-02T05:53:40.856317Z","shell.execute_reply.started":"2024-08-02T05:53:40.847785Z","shell.execute_reply":"2024-08-02T05:53:40.854952Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"BertConfig {\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.42.3\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Bu niteliklerin tümünün ne işe yaradığını henüz görmemiş olsanız da, bazılarını tanımanız gerekir: **hidden_size** niteliği hidden_states vektörünün boyutunu tanımlar ve **num_hidden_layers** Transformer modelinin sahip olduğu katman sayısını tanımlar.","metadata":{}},{"cell_type":"markdown","source":"## Different loading methods\n\nBir modeli varsayılan yapılandırmadan yeniden başlatmak, onu rastgele değerlerle başlatır:","metadata":{}},{"cell_type":"code","source":"config = BertConfig()\nmodel = BertModel(config)\n\n# Model is randomly initialized!","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:55:08.537136Z","iopub.execute_input":"2024-08-02T05:55:08.537578Z","iopub.status.idle":"2024-08-02T05:55:10.761586Z","shell.execute_reply.started":"2024-08-02T05:55:08.537543Z","shell.execute_reply":"2024-08-02T05:55:10.760313Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Model bu durumda kullanılabilir, ancak anlamsız çıktılar verecektir; önce eğitilmesi gerekir. Modeli elimizdeki görev üzerinde sıfırdan eğitebiliriz, ancak Bölüm 1'de gördüğünüz gibi, bu uzun zaman ve çok fazla veri gerektirir ve ihmal edilemez bir çevresel etkiye sahip olur. Gereksiz ve yinelenen çabalardan kaçınmak için, daha önce eğitilmiş modelleri paylaşabilmek ve yeniden kullanabilmek zorunludur.\n\nÖnceden eğitilmiş bir Transformer modelini yüklemek basittir - bunu from_pretrained() yöntemini kullanarak yapabiliriz:","metadata":{}},{"cell_type":"code","source":"model = BertModel.from_pretrained(\"bert-base-cased\")","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:56:32.578214Z","iopub.execute_input":"2024-08-02T05:56:32.578629Z","iopub.status.idle":"2024-08-02T05:56:34.994122Z","shell.execute_reply.started":"2024-08-02T05:56:32.578594Z","shell.execute_reply":"2024-08-02T05:56:34.992451Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a88e2be7a45e41ac9e8971f4f14691f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16ee34ab816f4586be1dc440e24745d9"}},"metadata":{}}]},{"cell_type":"markdown","source":"Daha önce gördüğünüz gibi, **BertModel**'i eşdeğer **AutoModel** sınıfı ile değiştirebiliriz. Şu andan itibaren bunu yapacağız çünkü bu, kontrol noktasından bağımsız kod üretir; kodunuz bir kontrol noktası için çalışıyorsa, diğeriyle sorunsuz bir şekilde çalışmalıdır. Bu, kontrol noktası benzer bir görev için eğitildiği sürece (örneğin, bir duygu analizi görevi) mimari farklı olsa bile geçerlidir.\n\nYukarıdaki kod örneğinde **BertConfig** kullanmadık ve bunun yerine **bert-base-cased** tanımlayıcısı aracılığıyla önceden eğitilmiş bir model yükledik. Bu, BERT'in yazarları tarafından eğitilmiş bir model kontrol noktasıdır; model kartında bununla ilgili daha fazla ayrıntı bulabilirsiniz.\n\nBu model şimdi kontrol noktasının tüm ağırlıkları ile başlatılmıştır. Eğitildiği görevler üzerinde çıkarım yapmak için doğrudan kullanılabilir ve ayrıca yeni bir görev üzerinde ince ayar yapılabilir. Sıfırdan eğitmek yerine önceden eğitilmiş ağırlıklarla eğiterek hızlı bir şekilde iyi sonuçlar elde edebiliriz.\n\nAğırlıklar indirildi ve varsayılan olarak *~/.cache/huggingface/transformers* olan önbellek klasöründe önbelleğe alındı (böylece **from_pretrained()** yöntemine gelecekteki çağrılar onları yeniden indirmeyecek). **HF_HOME** ortam değişkenini ayarlayarak önbellek klasörünüzü özelleştirebilirsiniz.\n\nModeli yüklemek için kullanılan tanımlayıcı, BERT mimarisiyle uyumlu olduğu sürece Model Hub'ındaki herhangi bir modelin tanımlayıcısı olabilir. Mevcut BERT kontrol noktalarının tüm listesine buradan ulaşabilirsiniz.","metadata":{}},{"cell_type":"markdown","source":"## Saving methods\n\nBir modeli kaydetmek, bir modeli yüklemek kadar kolaydır - **from_pretrained()** yöntemine benzer olan **save_pretrained()** yöntemini kullanırız:","metadata":{}},{"cell_type":"code","source":"model.save_pretrained(\"./\")","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:59:52.243950Z","iopub.execute_input":"2024-08-02T05:59:52.245343Z","iopub.status.idle":"2024-08-02T05:59:54.106140Z","shell.execute_reply.started":"2024-08-02T05:59:52.245297Z","shell.execute_reply":"2024-08-02T05:59:54.104962Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"config.json dosyasına bakarsanız, model mimarisini oluşturmak için gerekli öznitelikleri tanıyacaksınız. Bu dosya ayrıca, kontrol noktasının nereden kaynaklandığı ve kontrol noktasını en son kaydettiğinizde hangi Transformers sürümünü kullandığınız gibi bazı meta verileri de içerir.\n\npytorch_model.bin dosyası durum sözlüğü olarak bilinir; modelinizin tüm ağırlıklarını içerir. Bu iki dosya el ele gider; yapılandırma modelinizin mimarisini bilmek için gereklidir, model ağırlıkları ise modelinizin parametreleridir.","metadata":{}},{"cell_type":"markdown","source":"## Using a Transformer model for inference\n\nArtık bir modeli nasıl yükleyeceğinizi ve kaydedeceğinizi bildiğinize göre, bazı tahminler yapmak için onu kullanmayı deneyelim. Transformatör modelleri yalnızca sayıları işleyebilir - tokenizer'ın ürettiği sayılar. Ancak belirteçleri tartışmadan önce, modelin hangi girdileri kabul ettiğini inceleyelim.\n\nBelirteçler, girdileri uygun çerçevenin tensörlerine dönüştürme işini halledebilir, ancak neler olup bittiğini anlamanıza yardımcı olmak için girdileri modele göndermeden önce yapılması gerekenlere hızlıca bir göz atacağız.\n\nDiyelim ki birkaç dizimiz var:","metadata":{}},{"cell_type":"code","source":"sequences = [\"Hello!\", \"Cool.\", \"Nice!\"]","metadata":{"execution":{"iopub.status.busy":"2024-08-02T06:01:52.785383Z","iopub.execute_input":"2024-08-02T06:01:52.785839Z","iopub.status.idle":"2024-08-02T06:01:52.791914Z","shell.execute_reply.started":"2024-08-02T06:01:52.785803Z","shell.execute_reply":"2024-08-02T06:01:52.790506Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Tokenizer bunları tipik olarak girdi ID'leri olarak adlandırılan kelime indekslerine dönüştürür. Her dizi artık bir sayı listesidir! Elde edilen çıktı şöyledir:","metadata":{}},{"cell_type":"code","source":"encoded_sequences = [\n    [101, 7592, 999, 102],\n    [101, 4658, 1012, 102],\n    [101, 3835, 999, 102],\n]","metadata":{"execution":{"iopub.status.busy":"2024-08-02T06:02:08.757782Z","iopub.execute_input":"2024-08-02T06:02:08.758271Z","iopub.status.idle":"2024-08-02T06:02:08.765303Z","shell.execute_reply.started":"2024-08-02T06:02:08.758235Z","shell.execute_reply":"2024-08-02T06:02:08.763895Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Bu, kodlanmış dizilerin bir listesidir: listelerin bir listesi. Tensörler sadece dikdörtgen şekilleri kabul eder (matrisleri düşünün). Bu \"dizi\" zaten dikdörtgen şeklindedir, bu nedenle onu bir tensöre dönüştürmek kolaydır:","metadata":{}},{"cell_type":"code","source":"import torch\n\nmodel_inputs = torch.tensor(encoded_sequences)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T06:02:37.597735Z","iopub.execute_input":"2024-08-02T06:02:37.598138Z","iopub.status.idle":"2024-08-02T06:02:37.603753Z","shell.execute_reply.started":"2024-08-02T06:02:37.598107Z","shell.execute_reply":"2024-08-02T06:02:37.602515Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Using the tensors as inputs to the model\n\nTensörleri modelle birlikte kullanmak son derece basittir - modeli sadece girdilerle çağırırız:","metadata":{}},{"cell_type":"code","source":"output = model(model_inputs)\noutput","metadata":{"execution":{"iopub.status.busy":"2024-08-02T06:03:15.924029Z","iopub.execute_input":"2024-08-02T06:03:15.924544Z","iopub.status.idle":"2024-08-02T06:03:16.049353Z","shell.execute_reply.started":"2024-08-02T06:03:15.924498Z","shell.execute_reply":"2024-08-02T06:03:16.048022Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 4.4496e-01,  4.8276e-01,  2.7797e-01,  ..., -5.4032e-02,\n           3.9393e-01, -9.4770e-02],\n         [ 2.4943e-01, -4.4093e-01,  8.1772e-01,  ..., -3.1917e-01,\n           2.2992e-01, -4.1172e-02],\n         [ 1.3668e-01,  2.2518e-01,  1.4502e-01,  ..., -4.6915e-02,\n           2.8224e-01,  7.5566e-02],\n         [ 1.1789e+00,  1.6738e-01, -1.8187e-01,  ...,  2.4671e-01,\n           1.0441e+00, -6.1968e-03]],\n\n        [[ 3.6436e-01,  3.2465e-02,  2.0258e-01,  ...,  6.0111e-02,\n           3.2451e-01, -2.0996e-02],\n         [ 7.1866e-01, -4.8725e-01,  5.1740e-01,  ..., -4.4012e-01,\n           1.4553e-01, -3.7545e-02],\n         [ 3.3223e-01, -2.3271e-01,  9.4876e-02,  ..., -2.5268e-01,\n           3.2172e-01,  8.1110e-04],\n         [ 1.2523e+00,  3.5754e-01, -5.1320e-02,  ..., -3.7840e-01,\n           1.0526e+00, -5.6255e-01]],\n\n        [[ 2.4042e-01,  1.4718e-01,  1.2110e-01,  ...,  7.6062e-02,\n           3.3564e-01,  2.8262e-01],\n         [ 6.5701e-01, -3.2787e-01,  2.4968e-01,  ..., -2.5920e-01,\n           2.0175e-01,  3.3275e-01],\n         [ 2.0160e-01,  1.5783e-01,  9.8974e-03,  ..., -3.8851e-01,\n           4.1307e-01,  3.9732e-01],\n         [ 1.0175e+00,  6.4387e-01, -7.8147e-01,  ..., -4.2109e-01,\n           1.0925e+00, -4.8456e-02]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.6856,  0.5262,  1.0000,  ...,  1.0000, -0.6112,  0.9971],\n        [-0.6055,  0.4997,  0.9998,  ...,  0.9999, -0.6753,  0.9769],\n        [-0.7702,  0.5447,  0.9999,  ...,  1.0000, -0.4655,  0.9894]],\n       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"},"metadata":{}}]},{"cell_type":"markdown","source":"Model birçok farklı argüman kabul etse de, yalnızca girdi kimlikleri gereklidir. Diğer argümanların ne işe yaradığını ve ne zaman gerekli olduklarını daha sonra açıklayacağız, ancak önce bir Transformer modelinin anlayabileceği girdileri oluşturan tokenizer'lara daha yakından bakmamız gerekiyor.","metadata":{}}]}