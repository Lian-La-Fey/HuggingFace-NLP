{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# A full training\n\nŞimdi Trainer sınıfını kullanmadan son bölümde yaptığımızla aynı sonuçları nasıl elde edeceğimizi göreceğiz. Yine, bölüm 2'de veri işlemeyi yaptığınızı varsayıyoruz. Burada ihtiyacınız olacak her şeyi kapsayan kısa bir özet bulunmaktadır:","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoTokenizer, DataCollatorWithPadding\n\nraw_datasets = load_dataset(\"glue\", \"mrpc\")\ncheckpoint = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\n\ndef tokenize_function(example):\n    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n\n\ntokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:57:15.658757Z","iopub.execute_input":"2024-08-07T06:57:15.659118Z","iopub.status.idle":"2024-08-07T06:57:43.274453Z","shell.execute_reply.started":"2024-08-07T06:57:15.659089Z","shell.execute_reply":"2024-08-07T06:57:43.273513Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-08-07 06:57:24.912865: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-07 06:57:24.913007: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-07 06:57:25.039595: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/35.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"035e57bde152420abe3b71bedd2a3092"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/649k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"440913a8993c4b54873059e8f6c0deee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/75.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0048c89b2e743bb962e4c1568757cd4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/308k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7740291387ce4696a2f2c199ffcbf2d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a07c43df9f344cffb35611560d8f2001"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be7cfbf2f46945a9bab082fcdd90f05a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fd238663d1c4e9198b82de95d3c4395"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc58c70a7e934272abb864d9f61eb8f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4723952884e14276ba05f924908e96d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0510d08fbeb14a7eabd0a26323794180"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f9819784891478c8499c7376f53a7b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3668 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66b7bac65c2248fe8a4523486c61d688"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/408 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3329664d3e9f48ccbf8b42c6e26f9ad0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1725 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50fc2a01342141a084fc60818377d8db"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Prepare for training\n\nEğitim döngümüzü gerçekten yazmadan önce, birkaç nesne tanımlamamız gerekecek. Bunlardan ilki, yığınlar üzerinde yineleme yapmak için kullanacağımız dataloader'lardır. Ancak bu dataloader'ları tanımlamadan önce, Trainer'ın bizim için otomatik olarak yaptığı bazı şeylerle ilgilenmek için tokenized_datasets'ımıza biraz postprocessing uygulamamız gerekir. Özellikle, şunları yapmamız gerekir:\n\n- Modelin beklemediği değerlere karşılık gelen sütunları kaldırın (cümle1 ve cümle2 sütunları gibi).\n- Sütun etiketini labels olarak yeniden adlandırın (çünkü model argümanın labels olarak adlandırılmasını bekler).\n- Veri kümelerinin biçimini, listeler yerine PyTorch tensörleri döndürecek şekilde ayarlayın.\n\nBizim tokenized_datasets metodumuz bu adımların her biri için bir metoda sahiptir:","metadata":{}},{"cell_type":"code","source":"tokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:57:43.276298Z","iopub.execute_input":"2024-08-07T06:57:43.276754Z","iopub.status.idle":"2024-08-07T06:57:43.284269Z","shell.execute_reply.started":"2024-08-07T06:57:43.276718Z","shell.execute_reply":"2024-08-07T06:57:43.283410Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 3668\n    })\n    validation: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 408\n    })\n    test: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 1725\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets = tokenized_datasets.remove_columns([\"sentence1\", \"sentence2\", \"idx\"])\ntokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\ntokenized_datasets.set_format(\"torch\")\ntokenized_datasets[\"train\"].column_names","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:57:43.285426Z","iopub.execute_input":"2024-08-07T06:57:43.285770Z","iopub.status.idle":"2024-08-07T06:57:43.316916Z","shell.execute_reply.started":"2024-08-07T06:57:43.285739Z","shell.execute_reply":"2024-08-07T06:57:43.316065Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['labels', 'input_ids', 'token_type_ids', 'attention_mask']"},"metadata":{}}]},{"cell_type":"markdown","source":"Daha sonra sonucun yalnızca modelimizin kabul edeceği sütunlara sahip olup olmadığını kontrol edebiliriz:","metadata":{}},{"cell_type":"markdown","source":"Bu işlem tamamlandığına göre, dataloader'larımızı kolayca tanımlayabiliriz:","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(\n    tokenized_datasets[\"train\"], shuffle=True, batch_size=16, collate_fn=data_collator\n)\nval_dataloader = DataLoader(\n    tokenized_datasets[\"validation\"], batch_size=16, collate_fn=data_collator\n)\ntest_dataloader = DataLoader(\n    tokenized_datasets[\"test\"], batch_size=16, collate_fn=data_collator\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:57:43.318766Z","iopub.execute_input":"2024-08-07T06:57:43.319043Z","iopub.status.idle":"2024-08-07T06:57:43.324969Z","shell.execute_reply.started":"2024-08-07T06:57:43.319020Z","shell.execute_reply":"2024-08-07T06:57:43.324022Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Veri işlemede herhangi bir hata olup olmadığını hızlıca kontrol etmek için bir yığını şu şekilde inceleyebiliriz:","metadata":{}},{"cell_type":"code","source":"for batch in train_dataloader:\n    break\n{k: v.shape for k, v in batch.items()}","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:57:43.326441Z","iopub.execute_input":"2024-08-07T06:57:43.326764Z","iopub.status.idle":"2024-08-07T06:57:43.401125Z","shell.execute_reply.started":"2024-08-07T06:57:43.326740Z","shell.execute_reply":"2024-08-07T06:57:43.400183Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'labels': torch.Size([16]),\n 'input_ids': torch.Size([16, 81]),\n 'token_type_ids': torch.Size([16, 81]),\n 'attention_mask': torch.Size([16, 81])}"},"metadata":{}}]},{"cell_type":"markdown","source":"Eğitim dataloader'ı için shuffle=True ayarladığımız ve yığın içinde maksimum uzunluğa kadar dolgu yaptığımız için gerçek şekillerin muhtemelen sizin için biraz farklı olacağını unutmayın.\n\nArtık veri ön işlemeyi tamamen bitirdiğimize göre (herhangi bir ML uygulayıcısı için tatmin edici ancak zor bir hedef), modele dönelim. Modeli aynen önceki bölümde yaptığımız gibi örneklendiriyoruz:","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    checkpoint, num_labels=2\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:57:43.402273Z","iopub.execute_input":"2024-08-07T06:57:43.402623Z","iopub.status.idle":"2024-08-07T06:57:45.469657Z","shell.execute_reply.started":"2024-08-07T06:57:43.402589Z","shell.execute_reply":"2024-08-07T06:57:45.468849Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5fe4af39840483285cf7e5b5be7070c"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Eğitim sırasında her şeyin sorunsuz ilerleyeceğinden emin olmak için yığınımızı bu modele aktarıyoruz:","metadata":{}},{"cell_type":"code","source":"outputs = model(**batch)\nprint(outputs.loss, outputs.logits.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:57:45.470810Z","iopub.execute_input":"2024-08-07T06:57:45.471072Z","iopub.status.idle":"2024-08-07T06:57:47.529291Z","shell.execute_reply.started":"2024-08-07T06:57:45.471050Z","shell.execute_reply":"2024-08-07T06:57:47.528289Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"tensor(0.7047, grad_fn=<NllLossBackward0>) torch.Size([16, 2])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Tüm Transformers modelleri, etiketler sağlandığında kaybı döndürür ve ayrıca logitleri de alırız (partimizdeki her girdi için iki tane, yani 8 x 2 boyutunda bir tensör).\n\nEğitim döngümüzü yazmaya neredeyse hazırız! Sadece iki şey eksik: bir optimize edici ve bir öğrenme oranı zamanlayıcısı. Trainer'ın elle yaptığını kopyalamaya çalıştığımız için aynı varsayılanları kullanacağız. Trainer tarafından kullanılan optimize edici AdamW, Adam ile aynıdır, ancak ağırlık bozulması düzenlemesi için bir bükülme ile (bkz. Ilya Loshchilov ve Frank Hutter tarafından \"Decoupled Weight Decay Regularization\"):","metadata":{}},{"cell_type":"code","source":"import torch.optim as optim\n\noptimizer = optim.AdamW(model.parameters(), lr=5e-5)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:57:47.530465Z","iopub.execute_input":"2024-08-07T06:57:47.530783Z","iopub.status.idle":"2024-08-07T06:57:47.536926Z","shell.execute_reply.started":"2024-08-07T06:57:47.530756Z","shell.execute_reply":"2024-08-07T06:57:47.535880Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Son olarak, varsayılan olarak kullanılan öğrenme oranı zamanlayıcısı, maksimum değerden (5e-5) 0'a doğrusal bir düşüştür. Bunu doğru bir şekilde tanımlamak için, çalıştırmak istediğimiz epok sayısı ile eğitim yığınlarının sayısının (eğitim veri yükleyicimizin uzunluğu) çarpımı olan eğitim adımlarının sayısını bilmemiz gerekir. Trainer varsayılan olarak üç epok kullanır, bu yüzden biz de bunu takip edeceğiz:","metadata":{}},{"cell_type":"code","source":"from transformers import get_scheduler\n\nnum_epochs = 10\nnum_training_steps = num_epochs * len(train_dataloader)\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps,\n)\nprint(num_training_steps)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:57:47.538275Z","iopub.execute_input":"2024-08-07T06:57:47.538992Z","iopub.status.idle":"2024-08-07T06:57:47.560186Z","shell.execute_reply.started":"2024-08-07T06:57:47.538965Z","shell.execute_reply":"2024-08-07T06:57:47.559257Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"2300\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## The training loop\n\nSon bir şey: GPU'ya erişimimiz varsa onu kullanmak isteyeceğiz (CPU'da eğitim birkaç dakika yerine birkaç saat sürebilir). Bunu yapmak için modelimizi ve yığınlarımızı koyacağımız bir cihaz tanımlıyoruz:","metadata":{}},{"cell_type":"code","source":"import torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:57:47.562766Z","iopub.execute_input":"2024-08-07T06:57:47.563085Z","iopub.status.idle":"2024-08-07T06:57:47.862734Z","shell.execute_reply.started":"2024-08-07T06:57:47.563059Z","shell.execute_reply":"2024-08-07T06:57:47.861696Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"markdown","source":"Artık eğitime hazırız! Eğitimin ne zaman biteceğini anlamak için, tqdm kütüphanesini kullanarak eğitim adımı sayımızın üzerine bir ilerleme çubuğu ekliyoruz:","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n\ntrain_losses = []\nval_losses = []\nbest_val_loss = float('inf')\npatience = 3\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_running_loss = 0.0\n    \n    pbar = tqdm(enumerate(train_dataloader), desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\", total=len(train_dataloader))\n\n    for i, batch in pbar:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        optimizer.zero_grad()\n        outputs = model(**batch)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        train_running_loss += loss.item()\n\n        pbar.set_postfix(batch_loss=f\"{loss.item():.6f}\")\n\n    train_epoch_loss = train_running_loss / len(train_dataloader)\n    train_losses.append(train_epoch_loss)\n    \n    # Validation\n    model.eval()\n    val_running_loss = 0.0\n    with torch.no_grad():\n        for batch in val_dataloader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            outputs = model(**batch)\n            val_loss = outputs.loss\n            val_running_loss += val_loss.item()\n\n    val_epoch_loss = val_running_loss / len(val_dataloader)\n    val_losses.append(val_epoch_loss)\n    \n    print(f\"Epoch {epoch + 1}, Train Loss: {train_epoch_loss:.6f}, Val Loss: {val_epoch_loss:.6f}\")\n    \n    if val_epoch_loss < best_val_loss:\n        best_val_loss = val_epoch_loss\n        current_patience = 0\n    else:\n        current_patience += 1\n\n    if current_patience >= patience:\n        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n        break\n    ","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:57:47.863756Z","iopub.execute_input":"2024-08-07T06:57:47.864018Z","iopub.status.idle":"2024-08-07T07:00:01.869742Z","shell.execute_reply.started":"2024-08-07T06:57:47.863995Z","shell.execute_reply":"2024-08-07T07:00:01.868717Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"Epoch 1/10: 100%|██████████| 230/230 [00:32<00:00,  7.02batch/s, batch_loss=0.600931]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Train Loss: 0.521670, Val Loss: 0.397076\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10: 100%|██████████| 230/230 [00:32<00:00,  7.12batch/s, batch_loss=0.269887]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Train Loss: 0.282621, Val Loss: 0.435394\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10: 100%|██████████| 230/230 [00:32<00:00,  7.12batch/s, batch_loss=0.006450]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Train Loss: 0.126963, Val Loss: 0.455391\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10: 100%|██████████| 230/230 [00:32<00:00,  7.12batch/s, batch_loss=1.369809]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Train Loss: 0.070643, Val Loss: 0.478087\nEarly stopping triggered after 4 epochs.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Eğitim döngüsünün çekirdeğinin giriş bölümündekine çok benzediğini görebilirsiniz. Herhangi bir raporlama istemedik, bu nedenle bu eğitim döngüsü bize modelin nasıl ilerlediği hakkında hiçbir şey söylemeyecek. Bunun için bir değerlendirme döngüsü eklememiz gerekiyor.","metadata":{}},{"cell_type":"markdown","source":"## The evaluation loop\n\nDaha önce yaptığımız gibi, Evaluate kütüphanesi tarafından sağlanan bir metrik kullanacağız. **metric.compute()** yöntemini zaten görmüştük, ancak metrikler aslında **add_batch()** yöntemiyle tahmin döngüsünün üzerinden geçerken bizim için yığınları biriktirebilir. Tüm yığınları biriktirdikten sonra, metric.compute() ile nihai sonucu elde edebiliriz. İşte tüm bunların bir değerlendirme döngüsünde nasıl uygulanacağı:","metadata":{}},{"cell_type":"code","source":"!pip install -q evaluate","metadata":{"execution":{"iopub.status.busy":"2024-08-07T07:00:01.871051Z","iopub.execute_input":"2024-08-07T07:00:01.871404Z","iopub.status.idle":"2024-08-07T07:00:15.579320Z","shell.execute_reply.started":"2024-08-07T07:00:01.871370Z","shell.execute_reply":"2024-08-07T07:00:15.577915Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"glue\", \"mrpc\")\nmodel.eval()\n\nfor batch in test_dataloader:\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model(**batch)\n\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n\nmetric.compute()","metadata":{"execution":{"iopub.status.busy":"2024-08-07T07:00:15.581178Z","iopub.execute_input":"2024-08-07T07:00:15.581534Z","iopub.status.idle":"2024-08-07T07:00:21.344103Z","shell.execute_reply.started":"2024-08-07T07:00:15.581502Z","shell.execute_reply":"2024-08-07T07:00:21.342826Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.75k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cd7973ff9dc4d9bb53a5d946a79598c"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.8249275362318841, 'f1': 0.8747927031509122}"},"metadata":{}}]}]}