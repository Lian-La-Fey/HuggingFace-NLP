{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fine-tuning a model with the Trainer API\n\nTransformers, veri kümeniz üzerinde sağladığı önceden eğitilmiş modellerden herhangi birine ince ayar yapmanıza yardımcı olmak için bir Trainer sınıfı sağlar. Son bölümde tüm veri ön işleme çalışmalarını yaptıktan sonra, Trainer'ı tanımlamak için sadece birkaç adımınız kaldı. En zor kısım, CPU üzerinde çok yavaş çalışacağı için Trainer.train()'i çalıştıracak ortamı hazırlamak olacaktır. Eğer bir GPU kurulumunuz yoksa, Google Colab üzerinden ücretsiz GPU'lara veya TPU'lara erişim sağlayabilirsiniz.\n\nAşağıdaki kod örnekleri, önceki bölümdeki örnekleri zaten uyguladığınızı varsaymaktadır. Burada neye ihtiyacınız olduğunu özetleyen kısa bir özet bulunmaktadır:","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoTokenizer, DataCollatorWithPadding\n\nraw_datasets = load_dataset(\"glue\", \"mrpc\")\ncheckpoint = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\n\ndef tokenize_function(example):\n    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n\n\ntokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:35:16.676021Z","iopub.execute_input":"2024-08-07T06:35:16.676659Z","iopub.status.idle":"2024-08-07T06:35:42.019995Z","shell.execute_reply.started":"2024-08-07T06:35:16.676626Z","shell.execute_reply":"2024-08-07T06:35:42.018997Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-08-07 06:35:25.222035: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-07 06:35:25.222159: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-07 06:35:25.350885: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/35.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1ffde62e7634fa99894e0e853495b7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/649k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4471696da2f41a799c3d756a707f60a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/75.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67734f33cadb4f36abaa11a71266032c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/308k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb4c5469225643c2bb303fc8330838d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66f6b6c95dfe4a659cf66cea48ec5399"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a3bdb663ac749088e6fe7ef8f905e50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe6ed39e312d4a5b912b816139e7e37d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21e6651be7cc47c5a08ad901fb80c733"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4502224f614f414ca9435837cb5063e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b55737e895874275bc695f2ac87f9522"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9142e58e2674b9fbcdd54ddeeabc24c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3668 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6510393cde0e4aeaa6688a1023d4490a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/408 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49962310b0ae4fe5ac92ad82e0a64487"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1725 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef672f30049242c086599747e193b176"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Training\n\nEğiticimizi tanımlamadan önceki ilk adım, Eğiticinin eğitim ve değerlendirme için kullanacağı tüm hiperparametreleri içerecek bir TrainingArguments sınıfı tanımlamaktır. Sağlamanız gereken tek argüman, eğitilen modelin kaydedileceği bir dizin ve yol boyunca kontrol noktalarıdır. Geri kalan her şey için, temel bir ince ayar için oldukça iyi çalışması gereken varsayılanları bırakabilirsiniz.","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\"test-trainer\")","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:35:42.022019Z","iopub.execute_input":"2024-08-07T06:35:42.022631Z","iopub.status.idle":"2024-08-07T06:35:42.783017Z","shell.execute_reply.started":"2024-08-07T06:35:42.022596Z","shell.execute_reply":"2024-08-07T06:35:42.782250Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"İkinci adım modelimizi tanımlamaktır. Önceki bölümde olduğu gibi, iki etiketli AutoModelForSequenceClassification sınıfını kullanacağız:","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    checkpoint, num_labels=2\n).to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:35:42.784019Z","iopub.execute_input":"2024-08-07T06:35:42.784287Z","iopub.status.idle":"2024-08-07T06:35:45.208139Z","shell.execute_reply.started":"2024-08-07T06:35:42.784263Z","shell.execute_reply":"2024-08-07T06:35:45.206844Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f263d7cfb34a4b53884cf687a78fa385"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Bölüm 2'den farklı olarak, bu ön eğitimli modeli örneklendirdikten sonra bir uyarı aldığınızı fark edeceksiniz. Bunun nedeni, BERT'in cümle çiftlerini sınıflandırma konusunda ön eğitime tabi tutulmamış olmasıdır, bu nedenle ön eğitime tabi tutulmuş modelin başı atılmış ve yerine dizi sınıflandırmasına uygun yeni bir baş eklenmiştir. Uyarılar, bazı ağırlıkların kullanılmadığını (atılan ön eğitim kafasına karşılık gelenler) ve bazılarının rastgele başlatıldığını (yeni kafa için olanlar) gösterir. Sonunda sizi modeli eğitmeye teşvik eder ki şimdi yapacağımız da tam olarak budur.\n\nModelimizi oluşturduktan sonra, şimdiye kadar oluşturulmuş tüm nesneleri (model, training_args, eğitim ve doğrulama veri kümeleri, data_collator ve tokenizer) ona aktararak bir Trainer tanımlayabiliriz:","metadata":{}},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:35:45.210895Z","iopub.execute_input":"2024-08-07T06:35:45.211897Z","iopub.status.idle":"2024-08-07T06:35:46.109126Z","shell.execute_reply.started":"2024-08-07T06:35:45.211861Z","shell.execute_reply":"2024-08-07T06:35:46.108184Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Burada yaptığımız gibi tokenizer'ı geçtiğinizde, Trainer tarafından kullanılan varsayılan data_collator'ın daha önce tanımlandığı gibi bir DataCollatorWithPadding olacağını unutmayın, bu nedenle bu çağrıda data_collator=data_collator satırını atlayabilirsiniz. Bölüm 2'de işlemin bu kısmını göstermek yine de önemliydi!\n\nVeri kümemiz üzerinde modele ince ayar yapmak için Trainer'ımızın train() yöntemini çağırmamız yeterlidir:","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:35:46.110307Z","iopub.execute_input":"2024-08-07T06:35:46.110608Z","iopub.status.idle":"2024-08-07T06:38:38.316170Z","shell.execute_reply.started":"2024-08-07T06:35:46.110583Z","shell.execute_reply":"2024-08-07T06:38:38.315376Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240807_063614-kqcwge45</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/raspuntinov_ai/huggingface/runs/kqcwge45' target=\"_blank\">test-trainer</a></strong> to <a href='https://wandb.ai/raspuntinov_ai/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/raspuntinov_ai/huggingface' target=\"_blank\">https://wandb.ai/raspuntinov_ai/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/raspuntinov_ai/huggingface/runs/kqcwge45' target=\"_blank\">https://wandb.ai/raspuntinov_ai/huggingface/runs/kqcwge45</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1377/1377 02:05, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.528900</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.300300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1377, training_loss=0.34513849993936374, metrics={'train_runtime': 171.2448, 'train_samples_per_second': 64.259, 'train_steps_per_second': 8.041, 'total_flos': 405114969714960.0, 'train_loss': 0.34513849993936374, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"Bu, ince ayarı başlatacak (GPU'da birkaç dakika sürecektir) ve her 500 adımda bir eğitim kaybını rapor edecektir. Ancak modelinizin ne kadar iyi (veya kötü) performans gösterdiğini size söylemez. Bunun nedeni şudur:\n\nEvaluation_strategy'yi \"steps\" (her eval_steps'te değerlendirme) ya da \"epoch\" (her epoch'un sonunda değerlendirme) olarak ayarlayarak Eğiticiye eğitim sırasında değerlendirme yapmasını söylemedik. Söz konusu değerlendirme sırasında bir metrik hesaplaması için Eğiticiye bir compute_metrics() işlevi sağlamadık (aksi takdirde değerlendirme sadece kaybı yazdırırdı, ki bu çok sezgisel bir sayı değildir).","metadata":{}},{"cell_type":"markdown","source":"## Evaluation\n\nŞimdi kullanışlı bir **compute_metrics()** fonksiyonunu nasıl oluşturabileceğimizi ve bir sonraki eğitimimizde nasıl kullanabileceğimizi görelim. Fonksiyon bir **EvalPrediction nesnesi (predictions alanı ve label_ids alanı olan adlandırılmış bir tuple)** almalı ve dizeleri kayan değerlere eşleyen bir sözlük döndürmelidir (dizeler döndürülen metriklerin adları, kayan değerler ise değerleridir). Modelimizden bazı tahminler almak için **Trainer.predict()** komutunu kullanabiliriz:","metadata":{}},{"cell_type":"code","source":"predictions = trainer.predict(tokenized_datasets[\"validation\"])\nprint(predictions.predictions.shape, predictions.label_ids.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:38:38.317287Z","iopub.execute_input":"2024-08-07T06:38:38.317583Z","iopub.status.idle":"2024-08-07T06:38:39.514290Z","shell.execute_reply.started":"2024-08-07T06:38:38.317557Z","shell.execute_reply":"2024-08-07T06:38:39.513476Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"(408, 2) (408,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"predict() yönteminin çıktısı, üç alana sahip başka bir adlandırılmış tuple'dır: predictions, label_ids ve metrics. Metrics alanı, aktarılan veri kümesindeki kaybın yanı sıra bazı zaman metriklerini (toplamda ve ortalama olarak tahmin etmenin ne kadar sürdüğü) içerecektir. compute_metrics() fonksiyonumuzu tamamlayıp Trainer'a ilettiğimizde, bu alan compute_metrics() tarafından döndürülen metrikleri de içerecektir.\n\nGördüğünüz gibi, tahminler 408 x 2 şeklinde iki boyutlu bir dizidir (408, kullandığımız veri kümesindeki öğe sayısıdır). Bunlar, predict() işlevine aktardığımız veri kümesinin her bir öğesi için logitlerdir (önceki bölümde gördüğünüz gibi, tüm Transformer modelleri logit döndürür). Bunları etiketlerimizle karşılaştırabileceğimiz tahminlere dönüştürmek için, ikinci eksende maksimum değere sahip indeksi almamız gerekir:","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\npreds = np.argmax(predictions.predictions, axis=-1)\npreds","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:38:39.515305Z","iopub.execute_input":"2024-08-07T06:38:39.515590Z","iopub.status.idle":"2024-08-07T06:38:39.523841Z","shell.execute_reply.started":"2024-08-07T06:38:39.515564Z","shell.execute_reply":"2024-08-07T06:38:39.522946Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"array([1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n       1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n       1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n       1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n       0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n       1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n       0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1])"},"metadata":{}}]},{"cell_type":"raw","source":"Şimdi bu tahminleri etiketlerle karşılaştırabiliriz. **compute_metric()** fonksiyonumuzu oluşturmak için **Evaluate** kütüphanesindeki metriklere güveneceğiz. MRPC veri kümesiyle ilişkili metrikleri, veri kümesini yüklediğimiz gibi kolayca yükleyebiliriz, bu kez **evaluate.load()** işleviyle. Dönen nesne, metrik hesaplamasını yapmak için kullanabileceğimiz bir **compute()** yöntemine sahiptir:","metadata":{}},{"cell_type":"code","source":"!pip install -q evaluate","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:38:39.524888Z","iopub.execute_input":"2024-08-07T06:38:39.525156Z","iopub.status.idle":"2024-08-07T06:38:53.189923Z","shell.execute_reply.started":"2024-08-07T06:38:39.525123Z","shell.execute_reply":"2024-08-07T06:38:53.188775Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"glue\", \"mrpc\")\nmetric.compute(predictions=preds, references=predictions.label_ids)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:38:53.191611Z","iopub.execute_input":"2024-08-07T06:38:53.191922Z","iopub.status.idle":"2024-08-07T06:38:54.191627Z","shell.execute_reply.started":"2024-08-07T06:38:53.191892Z","shell.execute_reply":"2024-08-07T06:38:54.190552Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.75k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01a87610ce6e43a78dc2b55cebd48467"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.8651960784313726, 'f1': 0.9056603773584906}"},"metadata":{}}]},{"cell_type":"markdown","source":"Model kafasının rastgele başlatılması elde ettiği metrikleri değiştirebileceğinden, elde ettiğiniz kesin sonuçlar değişebilir. Burada, modelimizin doğrulama kümesinde %85,78'lik bir doğruluğa ve 89,97'lik bir F1 skoruna sahip olduğunu görebiliriz. Bunlar, GLUE kıyaslaması için MRPC veri kümesindeki sonuçları değerlendirmek için kullanılan iki metriktir. BERT makalesindeki tabloda temel model için 88,9 F1 skoru bildirilmiştir. Biz şu anda daha iyi sonucu açıklayan cased modelini kullanırken bu model uncased modeldi.\n\nHer şeyi bir araya getirerek `compute_metrics()` fonksiyonumuzu elde ediyoruz:","metadata":{}},{"cell_type":"code","source":"def compute_metrics(eval_preds):\n    metric = evaluate.load(\"glue\", \"mrpc\")\n    logits, labels = eval_preds\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:38:54.195261Z","iopub.execute_input":"2024-08-07T06:38:54.196047Z","iopub.status.idle":"2024-08-07T06:38:54.202356Z","shell.execute_reply.started":"2024-08-07T06:38:54.196012Z","shell.execute_reply":"2024-08-07T06:38:54.201566Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Ve her epoch'un sonunda metrikleri raporlamak için kullanıldığını görmek için, bu `compute_metrics()` işleviyle yeni bir `Trainer`'ı nasıl tanımladığımızı burada görebilirsiniz:","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    checkpoint, num_labels=2\n).to(\"cuda\")\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:38:54.203497Z","iopub.execute_input":"2024-08-07T06:38:54.203762Z","iopub.status.idle":"2024-08-07T06:38:54.714893Z","shell.execute_reply.started":"2024-08-07T06:38:54.203738Z","shell.execute_reply":"2024-08-07T06:38:54.713825Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Evaluation_strategy'si \"epoch\" olarak ayarlanmış yeni bir TrainingArguments ve yeni bir model oluşturduğumuza dikkat edin - aksi takdirde, zaten eğittiğimiz modelin eğitimine devam etmiş oluruz. Yeni bir eğitim çalıştırması başlatmak için şunu yürütürüz:","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:38:54.716130Z","iopub.execute_input":"2024-08-07T06:38:54.716495Z","iopub.status.idle":"2024-08-07T06:41:10.166369Z","shell.execute_reply.started":"2024-08-07T06:38:54.716436Z","shell.execute_reply":"2024-08-07T06:41:10.165331Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1377/1377 02:14, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.420780</td>\n      <td>0.821078</td>\n      <td>0.872600</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.569500</td>\n      <td>0.450426</td>\n      <td>0.813725</td>\n      <td>0.871622</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.348200</td>\n      <td>0.716702</td>\n      <td>0.828431</td>\n      <td>0.884868</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1377, training_loss=0.38946196889219376, metrics={'train_runtime': 134.9616, 'train_samples_per_second': 81.534, 'train_steps_per_second': 10.203, 'total_flos': 405114969714960.0, 'train_loss': 0.38946196889219376, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"Bu kez, eğitim kaybının yanı sıra her epoğun sonunda doğrulama kaybını ve ölçümlerini de rapor edecektir. Yine, ulaştığınız kesin Accuracy/F1 score, modelin rastgele kafa başlatması nedeniyle bizim bulduğumuzdan biraz farklı olabilir, ancak aynı top sahasında olmalıdır.\n\nEğitmen, birden fazla GPU veya TPU'da kutudan çıktığı gibi çalışacak ve karışık hassasiyetli eğitim gibi birçok seçenek sunacaktır (eğitim argümanlarınızda fp16 = True kullanın). Bölüm 10'da desteklediği her şeyin üzerinden geçeceğiz.\n\nBu, Trainer API kullanarak ince ayar yapmaya giriş bölümünü sonlandırmaktadır. Bunu en yaygın NLP görevleri için yapmanın bir örneği Bölüm 7'de verilecektir, ancak şimdilik aynı şeyi saf PyTorch'ta nasıl yapacağımıza bakalım.","metadata":{}}]}